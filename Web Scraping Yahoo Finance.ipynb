{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto de Web Scraping com Python\n",
    "\n",
    "\n",
    "Este projeto tem como objetivo demonstrar um web scraper em Python para coletar dados financeiros de ações da bolsa de valores e lista-los em tabelas. Utilizaremos as bibliotecas pandas, requests e BeautifulSoup para obter os dados históricos de preços de ações do site Yahoo Finance.\n",
    "\n",
    "## Funcionalidades\n",
    "\n",
    "- Importação de uma base de ações a partir de um arquivo Excel.\n",
    "- Construção das URLs para acesso aos dados no Yahoo Finance.\n",
    "- Captura das páginas web e transformação em objetos BeautifulSoup.\n",
    "- Extração de métricas financeiras e dividendos das páginas web.\n",
    "- Armazenamento das métricas e dividendos em DataFrames pandas.\n",
    "- Tratamento de erros e armazenamento de informações rejeitadas.\n",
    "- Estatísticas básicas dos dados\n",
    "\n",
    "## Requisitos\n",
    "\n",
    "Para executar o projeto, é necessário ter as seguintes bibliotecas:\n",
    "\n",
    "- pandas\n",
    "- request, \n",
    "- BeautifulSoup\n",
    "- datetime\n",
    "\n",
    "Você pode instalar as bibliotecas necessárias executando o seguinte comando:\n",
    "\n",
    "```python\n",
    "pip install pandas requests beautifulsoup4 datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports necessários\n",
    "from datetime import datetime #Tempo e data\n",
    "IP=datetime.now()\n",
    "import pandas as pd # Manipulação de tabelas\n",
    "import requests # Captura do texto HTML do site\n",
    "from bs4 import BeautifulSoup # Processamento do HTML do site\n",
    "\n",
    "import matplotlib.pyplot as plt #gráficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração dos dados e pré-processamento.\n",
    "\n",
    "\n",
    "\n",
    "Aqui, importamos a base de ações a partir de um arquivo Excel chamado \"Ações.xlsx\" utilizando a função read_excel da biblioteca pandas.\n",
    "\n",
    "Na sequência, será adicionado nome da ação no URL pois ações brasileiras terminam com \".SA\". \n",
    "\n",
    "O texto da coluna \"URL\" foi retirado da tabela de métricas de ações no site do Yahoo Finance. \n",
    "\n",
    "A coluna \"Soup\" é o resultado das capturas de HTMLs pelo requests e o processamento destes pelo BeautifulSoup\n",
    "\n",
    "A coluna \"Tempo\" representa o tempo de demora de processamento de cada célula da coluna \"Soup\", em segundos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando a base de ações\n",
    "\n",
    "AÇ=pd.read_excel(\"Ações.xlsx\")\n",
    "\n",
    "\n",
    "#AÇ=AÇ.iloc[:5,:] #retirar após testes (termo utilizado para diminuir a quantidade de ações para 5)\n",
    "\n",
    "#criando coluna do texto da ação no URL\n",
    "AÇ['N_URL']=[AÇ.iloc[:,1][i]+\".SA\" if j == \"Brasileira\" else AÇ.iloc[:,1][i] for i,j in enumerate(AÇ.iloc[:,0])]\n",
    "\n",
    "#criando coluna do texto da no URL no Yahoo\n",
    "AÇ['URL']=\"https://uk.finance.yahoo.com/quote/\"+AÇ.N_URL+\"/history?period1=1309305600&period2=1685577600&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true\"\n",
    "\n",
    "#capturando as requests e transformando em soup\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "}\n",
    "\n",
    "Soup=[]\n",
    "Tempo=[]\n",
    "for url in AÇ.URL:\n",
    "    Inicio=datetime.now()\n",
    "    Soup+=[BeautifulSoup(requests.get(url,headers=headers).text, 'html.parser')]\n",
    "    Fim=datetime.now()\n",
    "    Tempo+=[(Fim-Inicio).total_seconds()]\n",
    "AÇ['Soup']=Soup\n",
    "AÇ['Tempo']=Tempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento dos dados\n",
    "\n",
    "\n",
    "\n",
    "Nesta etapa de processamento dos dados, utilizamos a manipulação de strings para coletar informações sobre ações. \n",
    "\n",
    "Percorremos cada elemento da lista de ações, capturando e tratando os dados relevantes. \n",
    "\n",
    "Criamos dataframes para armazenar as métricas das ações e os dividendos associados, concatenando-os aos dataframes principais. \n",
    "\n",
    "Também identificamos e registramos os elementos atípicos ou com formato de dados inesperado. \n",
    "\n",
    "Ao final, temos os dataframes \"Métricas\", \"Dividendos\" e \"rejeitos\". Essa etapa é essencial para extrair informações das páginas web e organizar os dados para análises futuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split duplo\n",
    "def splitduplo(termo1, termo2, string):\n",
    "    return string.split(termo1)[1].split(termo2)[0]\n",
    "\n",
    "\n",
    "#lista de qualquer formato para lista de strings\n",
    "def listastr(lista):\n",
    "    return [str(s).replace(\",\",\"\") for s in list(lista)]\n",
    "\n",
    "#função principaç\n",
    "def trazervalores(AÇ):\n",
    "    Métricas = pd.DataFrame()\n",
    "    Dividendos = pd.DataFrame()\n",
    "    rejeitos = pd.DataFrame(columns=['Elemento', 'Ação'])\n",
    "    \n",
    "    # Loop para percorrer cada linha do DataFrame AÇ\n",
    "    for N in range(len(AÇ.loc[:, 'Soup'])):\n",
    "        # Encontra todos os elementos com a classe \"BdT Bdc($seperatorColor) Ta(end) Fz(s) Whs(nw)\" no objeto Soup\n",
    "        elements = AÇ.loc[N, 'Soup'].find_all(class_=\"BdT Bdc($seperatorColor) Ta(end) Fz(s) Whs(nw)\")\n",
    "        \n",
    "        # Loop para percorrer cada elemento encontrado\n",
    "        for i in elements:\n",
    "            Inicio=datetime.now()\n",
    "    # Verifica se o elemento possui 7 tags \"span\", que é o tamanho da tabela no Yahoo finance que tem as métricas das ações\n",
    "            if len(i.find_all(\"span\")) == 7:\n",
    "                informações1 = listastr(i)\n",
    "                \n",
    "                # Extrai os valores utilizando a função splitduplo\n",
    "                Data =  datetime.strptime(splitduplo(\"<span>\", \"</span>\", informações1[0]),\"%d %b %Y\")\n",
    "                Open = float(splitduplo(\"<span>\", \"</span>\", informações1[1]))\n",
    "                High = float(splitduplo(\"<span>\", \"</span>\", informações1[2]))\n",
    "                Low = float(splitduplo(\"<span>\", \"</span>\", informações1[3]))\n",
    "                Close = float(splitduplo(\"<span>\", \"</span>\", informações1[4]))\n",
    "                AdjClose = float(splitduplo(\"<span>\", \"</span>\", informações1[5]))\n",
    "                Volume = float(splitduplo(\"<span>\", \"</span>\", informações1[6]))\n",
    "                Fim=datetime.now()\n",
    "                # Cria um DataFrame temporário com as informações extraídas\n",
    "                MétricasTemp = pd.DataFrame({\n",
    "                    'Data': [Data],\n",
    "                    \"Open\": [Open],\n",
    "                    \"High\": [High],\n",
    "                    \"Low\": [Low],\n",
    "                    \"Close\": [Close],\n",
    "                    \"AdjClose\": [AdjClose],\n",
    "                    \"Volume\": [Volume],\n",
    "                    \"Tempo\":[(Fim-Inicio).total_seconds()],\n",
    "                    \"Ação\": [AÇ.loc[N, 'Ação']]\n",
    "                })\n",
    "                \n",
    "                # Concatena o DataFrame temporário com o DataFrame Métricas\n",
    "                Métricas = pd.concat([Métricas, MétricasTemp], ignore_index=True)\n",
    "            \n",
    "            # Verifica se o elemento possui 2 tags \"span\", que é o tamanho da linha quando há dividendos no dia\n",
    "            elif len(i.find_all(\"span\")) == 2:\n",
    "                try:\n",
    "                    informações2 = listastr(i)\n",
    "\n",
    "                    # Extrai os valores utilizando a função splitduplo\n",
    "                    DataDoDividendo = datetime.strptime(splitduplo(\"<span>\", \"</span>\", informações1[0]),\"%d %b %Y\")\n",
    "                    ValorDoDividendo = splitduplo(\"<strong>\", \"</strong>\", informações2[1])\n",
    "                    Classe=splitduplo(\"</strong>\", \"</span>\", informações2[1]).replace(\"<span>\",\"\")\n",
    "                    \n",
    "                    # Cria um DataFrame temporário com as informações extraídas\n",
    "                    DividendosTemp = pd.DataFrame({\n",
    "                        'Data': [DataDoDividendo],\n",
    "                        \"Valor do dividendo\": [ValorDoDividendo],\n",
    "                        \"Classe\":[Classe],\n",
    "                        \"Ação\": [AÇ.loc[N, 'Ação']]\n",
    "                        \n",
    "                    })\n",
    "\n",
    "                    # Concatena o DataFrame temporário com o DataFrame Dividendos\n",
    "                    Dividendos = pd.concat([Dividendos, DividendosTemp], ignore_index=True)\n",
    "                    \n",
    "                    \n",
    "                #célula para identificar erros\n",
    "                except Exception as e:\n",
    "                    print(AÇ.loc[N, 'Ação'])\n",
    "                    print(e)\n",
    "                    print((AÇ.loc[N, 'URL']))\n",
    "            # Caso o elemento não se encaixe nos casos anteriores, é considerado um \"rejeito\" e é adicionado ao DataFrame rejeitos\n",
    "            else:\n",
    "                \n",
    "                #Dataframe com pontos discrepantes\n",
    "                rejeitos = pd.concat([rejeitos, pd.DataFrame([[i, AÇ.loc[N, 'Ação']]], columns=['Elemento', 'Ação'])])\n",
    "    return Métricas,Dividendos,rejeitos\n",
    "\n",
    "\n",
    "Métricas,Dividendos,rejeitos=trazervalores(AÇ)\n",
    "PF=datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duração total do processo:\n",
      "0:07:54.781528\n",
      "Análise Exploratória - DataFrame 1\n",
      "-----------------------------\n",
      "Contagem de Valores em 'B_ou_E':\n",
      "Estrangeira    135\n",
      "Brasileira      65\n",
      "Name: B_ou_E, dtype: int64\n",
      "\n",
      "Contagem de Valores em 'Setor':\n",
      "Tecnologia             26\n",
      "Energia                25\n",
      "Financeiro             22\n",
      "Saúde                  13\n",
      "Varejo                 13\n",
      "Farmacêutico           11\n",
      "Telecomunicações        8\n",
      "Indústria               8\n",
      "Seguros                 7\n",
      "Imobiliário             7\n",
      "Entretenimento          5\n",
      "Aeroespacial            4\n",
      "Alimentação             4\n",
      "Bebidas                 4\n",
      "Bens de Consumo         3\n",
      "Transporte              3\n",
      "Papel e Celulose        3\n",
      "Automotivo              3\n",
      "Turismo                 3\n",
      "Químicos                3\n",
      "Vestuário               3\n",
      "Locação de Veículos     2\n",
      "Infraestrutura          2\n",
      "Siderurgia              2\n",
      "Alimentos               2\n",
      "Mineração               2\n",
      "Tabaco                  2\n",
      "Serviços de TI          1\n",
      "Construção Civil        1\n",
      "Petroquímica            1\n",
      "Farmácias               1\n",
      "Logística               1\n",
      "Cosméticos              1\n",
      "Embalagens              1\n",
      "Viagens e Turismo       1\n",
      "Agricultura             1\n",
      "Holding                 1\n",
      "Name: Setor, dtype: int64\n",
      "\n",
      "Média do tempo de extração e pré-processamento em segundos:\n",
      "2.1844792450000003\n",
      "\n",
      "\n",
      "\n",
      "Estatísticas Descritivas:\n",
      "            Tempo\n",
      "count  200.000000\n",
      "mean     2.184479\n",
      "std      0.488094\n",
      "min      1.216326\n",
      "25%      1.900745\n",
      "50%      2.123323\n",
      "75%      2.385198\n",
      "max      4.163997\n",
      "\n",
      "\n",
      "Análise Exploratória - DataFrame 2\n",
      "-----------------------------\n",
      "Número de Valores nulos em 'Ação': Data        17766\n",
      "Open        17766\n",
      "High        17766\n",
      "Low         17766\n",
      "Close       17766\n",
      "AdjClose    17766\n",
      "Volume      17766\n",
      "Tempo       17766\n",
      "Ação        17766\n",
      "dtype: int64\n",
      "Data do ínicio do período de análise: 2023-01-05 00:00:00\n",
      "Data do final do período de análise 2023-06-02 00:00:00\n",
      "\n",
      "\n",
      "\n",
      "Média do tempo de extração e pré-processamento em segundos:\n",
      "Tempo    0.019964\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Análise Exploratória - DataFrame 3\n",
      "-----------------------------\n",
      "Número de Valores Nulos em 'Valor do dividendo': Data                  232\n",
      "Valor do dividendo    232\n",
      "Classe                232\n",
      "Ação                  232\n",
      "dtype: int64\n",
      "Última Data Registrada: 2023-05-31 00:00:00\n",
      "\n",
      "\n",
      "Análise Exploratória - DataFrame 4\n",
      "-----------------------------\n",
      "Número de Elementos: 2\n",
      "Número de Ações Exclusivas: 2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "contagem_B_ou_E = AÇ['B_ou_E'].value_counts()\n",
    "contagem_Setor = AÇ['Setor'].value_counts()\n",
    "estatisticas_numericas = AÇ.describe()\n",
    "\n",
    "print('Duração total do processo:')\n",
    "print(PF-IP)\n",
    "\n",
    "\n",
    "print(\"Análise Exploratória - DataFrame 1\")\n",
    "print(\"-----------------------------\")\n",
    "print(\"Contagem de Valores em 'B_ou_E':\")\n",
    "print(contagem_B_ou_E)\n",
    "print(\"\\nContagem de Valores em 'Setor':\")\n",
    "print(contagem_Setor)\n",
    "\n",
    "print(\"\\nMédia do tempo de extração e pré-processamento em segundos:\")\n",
    "print(AÇ['Tempo'].mean())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"\\nEstatísticas Descritivas:\")\n",
    "print(estatisticas_numericas)\n",
    "print(\"\\n\")\n",
    "\n",
    "# DataFrame 2\n",
    "duplicados_Ação = Métricas.isnull().count()\n",
    "\n",
    "\n",
    "print(\"Análise Exploratória - DataFrame 2\")\n",
    "print(\"-----------------------------\")\n",
    "print(\"Número de Valores nulos em 'Ação':\", duplicados_Ação)\n",
    "print(\"Data do ínicio do período de análise:\", Métricas['Data'].min())\n",
    "print(\"Data do final do período de análise\", Métricas['Data'].max())\n",
    "print(\"\\n\")\n",
    "print(\"\\nMédia do tempo de extração e pré-processamento em segundos:\")\n",
    "print(Métricas[['Ação','Tempo']].groupby('Ação').sum().mean())\n",
    "print(\"\\n\")\n",
    "\n",
    "# DataFrame 3\n",
    "valores_nulos = Dividendos.isnull().count()\n",
    "#media_dividendos = Dividendos[['Classe']==' Dividend']['Valor do dividendo'].astype(float).mean()\n",
    "ultima_data = Dividendos['Data'].max()\n",
    "\n",
    "print(\"Análise Exploratória - DataFrame 3\")\n",
    "print(\"-----------------------------\")\n",
    "print(\"Número de Valores Nulos em 'Valor do dividendo':\", valores_nulos)\n",
    "#print(\"Valor Médio de Dividendos:\", media_dividendos)\n",
    "print(\"Última Data Registrada:\", ultima_data)\n",
    "print(\"\\n\")\n",
    "\n",
    "# DataFrame 4\n",
    "num_elementos = len(rejeitos)\n",
    "num_acoes_exclusivas = rejeitos['Ação'].nunique()\n",
    "\n",
    "print(\"Análise Exploratória - DataFrame 4\")\n",
    "print(\"-----------------------------\")\n",
    "print(\"Número de Elementos:\", num_elementos)\n",
    "print(\"Número de Ações Exclusivas:\", num_acoes_exclusivas)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "O projeto foi concluído com sucesso, resultando em quatro dataframes. O tempo de execução do processo inteiro foi de 07 minutos e 54 segundos, e, para melhorar o tempo, será necessário modificações no código. A utilização de listas talvez prejudique a performance, assim como a quantidade de loops.\n",
    "\n",
    "A partir do funcionamento do código, foi possível coletar apenas os dados entre 01/05/2023 e 02/06/2023. Para superar esta barreira e adquirir todos os dados possíveis, será necessário o conhecimento da formação do URL, que estipula o período, e o uso de alguma outra biblioteca, como o Selenium, para alançar os dados que são enviados ao usuário após rolar a página até o fim.\n",
    "\n",
    "Apesar dos pontos de potenciais melhorias que serão descritos abaixo, o código funciona efetivamente. A análise pode ser mais robusta pois a atual não entrega uma completude no entendimento dos dados.\n",
    "\n",
    "\n",
    "### Pontos de melhoria\n",
    "\n",
    "- Otimização do tempo de execução: \n",
    "\n",
    "É necessário rever o código e identificar possíveis áreas de melhoria para reduzir o tempo total de execução. A utilização de listas e loops pode afetar a performance, portanto, considerar abordagens mais eficientes pode ajudar a melhorar o tempo de processamento.\n",
    "\n",
    "- Aquisição de dados completos: \n",
    "\n",
    "Identificou-se uma limitação na coleta de dados, onde apenas os registros entre 01/05/2023 e 02/06/2023 foram obtidos. Para superar essa limitação, é recomendado explorar a estrutura do URL utilizado para a coleta de dados e investigar se é possível configurar um período mais abrangente. Além disso, o uso de bibliotecas como o Selenium pode ser necessário para automatizar a rolagem da página e obter todos os dados disponíveis.\n",
    "\n",
    "- Organização do código: \n",
    "\n",
    "Refatorar o código para torná-lo mais modular e legível. Isso inclui separar as funcionalidades em funções reutilizáveis, adicionar comentários explicativos e seguir as boas práticas de codificação. Uma estrutura de código bem organizada facilita a manutenção, depuração e colaboração com outros desenvolvedores.\n",
    "\n",
    "- Visualização de dados: \n",
    "\n",
    "Aprimorar a análise exploratória incorporando visualizações de dados por meio de gráficos. Utilize bibliotecas como Matplotlib, Seaborn ou Plotly para criar gráficos informativos, como gráficos de barras, gráficos de dispersão, histogramas, entre outros. Essas visualizações permitem identificar padrões, tendências e relações nos dados, facilitando a compreensão e comunicação dos resultados. Além disso, considere a criação de gráficos interativos que permitam a exploração dos dados de forma dinâmica. A inclusão desses gráficos irá enriquecer a análise exploratória, tornando-a mais impactante e compreensível para os usuários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
